# interface.py
import streamlit as st
import requests
import json
from groq import Groq # Import Groq SDK

# --- PAGE CONFIGURATION (MUST BE THE FIRST STREAMLIT COMMAND) ---
st.set_page_config(page_title="G√©n√©rateur & V√©rificateur de Questions", layout="wide")

# --- Configuration ---
FLASK_API_BASE_URL = "http://localhost:5000" # Ajustez si votre API Flask est ailleurs
QCM_ENDPOINT = f"{FLASK_API_BASE_URL}/generate_qcm"
FITB_ENDPOINT = f"{FLASK_API_BASE_URL}/generate_fitb"

# --- Initialize Groq Client ---
# This section will now run AFTER st.set_page_config
groq_client = None
GROQ_API_KEY = None

try:
    if "GROQ_API_KEY" in st.secrets:
        GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
    else:
        st.sidebar.warning("GROQ_API_KEY non trouv√© dans les secrets. V√©rification d√©sactiv√©e.")

    if GROQ_API_KEY:
        groq_client = Groq(api_key=GROQ_API_KEY)
        st.sidebar.success("Client Groq initialis√©.")
    elif "GROQ_API_KEY" in st.secrets: # Only show missing key warning if it was expected
        st.sidebar.warning("Client Groq non initialis√© (probl√®me de cl√© API).")

except Exception as e:
    st.sidebar.error(f"Erreur initialisation client Groq : {e}")
    groq_client = None


# --- Helper Function to Call Flask API ---
def call_flask_api(endpoint_url, text_input):
    payload = {"texte": text_input}
    headers = {"Content-Type": "application/json"}
    try:
        response = requests.post(endpoint_url, data=json.dumps(payload), headers=headers, timeout=180)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        st.error(f"Erreur de requ√™te API : {e}")
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_details = e.response.json()
                st.error(f"D√©tails de l'erreur API : {error_details}")
                return {"error": str(e), "details": error_details, "raw_output": "Erreur API"}
            except json.JSONDecodeError:
                st.error(f"Contenu de l'erreur API (non JSON) : {e.response.text}")
                return {"error": str(e), "raw_output": e.response.text}
        return {"error": str(e), "raw_output": "Erreur de connexion API"}
    except json.JSONDecodeError:
        st.error("Erreur de d√©codage de la r√©ponse JSON de l'API.")
        return {"error": "Erreur D√©codage JSON", "raw_output": "JSON invalide de l'API"}

# --- Helper Function to Call Groq API for Verification (in French) ---
def call_groq_for_verification(context_text, generated_question_data, question_type):
    if not groq_client:
        return "Client Groq non initialis√©. Veuillez vous assurer que GROQ_API_KEY est configur√© dans .streamlit/secrets.toml et que le client est bien d√©marr√©."

    q_data = generated_question_data # raccourci
    prompt_parts = [
        f"Vous √™tes un assistant IA expert en √©valuation de questions p√©dagogiques ({question_type}). **Soyez direct, concis et r√©pondez en fran√ßais.** √âvitez les phrases introductives ou les commentaires superflus.",
        "Analysez la question suivante bas√©e sur le texte original fourni.",
        "\n**Texte Original Fourni :**",
        "--- TEXTE ORIGINAL D√âBUT ---",
        context_text,
        "--- TEXTE ORIGINAL FIN ---",
        "\n",
        f"**Question ({question_type}) G√©n√©r√©e √† √âvaluer :**",
        f"Question : {q_data.get('question', 'N/A')}",
        f"Option A : {q_data.get('A', 'N/A')}",
        f"Option B : {q_data.get('B', 'N/A')}",
        f"Option C : {q_data.get('C', 'N/A')}",
        f"Option D : {q_data.get('D', 'N/A')}",
        f"R√©ponse Attendue (par l'IA g√©n√©ratrice) : {q_data.get('reponse', 'N/A')}",
        "\n",
        "**Crit√®res d'√âvaluation (R√©pondez de mani√®re concise pour chaque point) :**",
        "1.  **Exactitude & Justification :** La question et la r√©ponse attendue sont-elles exactes par rapport au texte ? Justifiez bri√®vement.",
        "2.  **Clart√© & Ambigu√Øt√© :** La question est-elle claire ? Y a-t-il des ambigu√Øt√©s ?",
        "3.  **Pertinence :** La question est-elle pertinente par rapport aux informations cl√©s du texte ?",
        "4.  **Qualit√© des Options (Distracteurs) :** Les distracteurs sont-ils plausibles mais incorrects ? Y a-t-il des probl√®mes avec les options ?",
        "5.  **Sp√©cificit√©s FITB (si applicable) :** Le blanc est-il bien choisi ? La phrase est-elle naturelle ?",
        "\n",
        "**Format de R√©ponse Exig√© (Direct et Structur√©, en fran√ßais) :**",
        "   - **Avis G√©n√©ral Concis :** (Ex: Excellente, Bonne avec r√©serves, M√©diocre, Probl√©matique - ajouter 1-2 mots cl√©s si besoin).",
        "   - **Analyse Point par Point (Directe) :**",
        "     1.  Exactitude : [Votre √©valuation concise]",
        "     2.  Clart√© : [Votre √©valuation concise]",
        "     3.  Pertinence : [Votre √©valuation concise]",
        "     4.  Options : [Votre √©valuation concise]",
        "     5.  FITB (si applicable) : [Votre √©valuation concise]",
        "   - **Probl√®mes Principaux (Liste √† puces si besoin) :**",
        "     - [Probl√®me 1 s'il y en a]",
        "     - [Probl√®me 2 s'il y en a]",
        "   - **Suggestions d'Am√©lioration (Si et seulement si n√©cessaire, soyez bref) :**",
        "     *   Question R√©vis√©e : [Nouvelle question si besoin]",
        "     *   Options R√©vis√©es : A) ..., B) ..., C) ..., D) ...",
        "     *   R√©ponse Corrig√©e : [Lettre]",
        "     (Si aucune am√©lioration majeure n'est n√©cessaire, indiquez 'Original satisfaisant' ou similaire).",
        "\n**Priorit√© √† la concision et √† la pertinence. √âvitez toute formulation excessive.**"
    ]
    full_prompt = "\n".join(prompt_parts)

    try:
        chat_completion = groq_client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "Vous √™tes un √©valuateur IA de questions. Soyez analytique, direct, concis et r√©pondez uniquement en fran√ßais. Fournissez des √©valuations structur√©es sans phrases inutiles."
                },
                {
                    "role": "user",
                    "content": full_prompt,
                }
            ],
            model="llama3-70b-8192", # llama3-8b-8192 might also work and be faster if 70b is too slow
            temperature=0.1, # Very low temperature for factual, less "creative" or verbose responses
            max_tokens=1500, # Should be enough for a concise but complete analysis
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"Erreur lors de l'appel √† l'API Groq : {str(e)}"
    if not groq_client:
        return "Client Groq non initialis√©. Veuillez vous assurer que GROQ_API_KEY est configur√© dans .streamlit/secrets.toml et que le client est bien d√©marr√©."

    q_data = generated_question_data # raccourci
    prompt_parts = [
        f"Vous √™tes un assistant IA expert, sp√©cialis√© dans l'√©valuation de la qualit√© des questions p√©dagogiques ({question_type}) g√©n√©r√©es √† partir d'un texte fourni. **Veuillez r√©pondre imp√©rativement et int√©gralement en fran√ßais.**",
        "Voici le texte original sur lequel la question est bas√©e :",
        "--- TEXTE ORIGINAL D√âBUT ---",
        context_text,
        "--- TEXTE ORIGINAL FIN ---",
        "\n",
        f"Voici la question de type '{question_type}' g√©n√©r√©e par une autre IA :",
        f"Question : {q_data.get('question', 'N/A')}",
        f"Option A : {q_data.get('A', 'N/A')}",
        f"Option B : {q_data.get('B', 'N/A')}",
        f"Option C : {q_data.get('C', 'N/A')}",
        f"Option D : {q_data.get('D', 'N/A')}",
        f"L'IA g√©n√©ratrice affirme que la bonne r√©ponse est : {q_data.get('reponse', 'N/A')}",
        "\n",
        "Votre t√¢che est d'√©valuer de mani√®re critique cette question g√©n√©r√©e. Veuillez consid√©rer les points suivants :",
        "1.  **Exactitude et Justification :** La question est-elle factuellement correcte en se basant *uniquement* sur le texte fourni ? La 'bonne r√©ponse' indiqu√©e est-elle vraiment correcte selon le texte ? Expliquez votre raisonnement.",
        "2.  **Clart√© et Ambigu√Øt√© :** La question est-elle formul√©e de mani√®re claire et sans ambigu√Øt√© ? Y a-t-il des termes qui pourraient √™tre mal interpr√©t√©s ?",
        "3.  **Pertinence :** La question teste-t-elle une information ou un concept significatif du texte, ou est-elle triviale ?",
        "4.  **Qualit√© des Options (Distracteurs) :**",
        "    *   Les options incorrectes (distracteurs) sont-elles suffisamment plausibles pour d√©fier quelqu'un qui n'a pas bien compris le texte, mais clairement fausses pour quelqu'un qui l'a compris ?",
        "    *   Certains distracteurs sont-ils trop √©videmment faux ou trop proches d'√™tre corrects (ce qui pourrait rendre la question confuse ou avoir plusieurs 'bonnes' r√©ponses d'un certain point de vue) ?",
        "5.  **Sp√©cificit√©s FITB (si applicable) :** S'il s'agit d'une question √† compl√©ter (Texte √† Trous), le blanc cible-t-il un mot-cl√© ou un concept appropri√© ? La structure de la phrase autour du blanc est-elle naturelle ?",
        "\n",
        "**Exigences pour la R√©ponse (en fran√ßais) :**",
        "Veuillez structurer votre analyse comme suit :",
        "   - **Avis G√©n√©ral :** Un bref r√©sum√© de la qualit√© de la question (par exemple, Excellente, Bonne, Passable, M√©diocre, Probl√©matique).",
        "   - **Analyse D√©taill√©e :** Abordez chacun des points num√©rot√©s ci-dessus avec des commentaires sp√©cifiques et des justifications bas√©es sur le texte.",
        "   - **Probl√®mes Identifi√©s :** Listez clairement tous les probl√®mes que vous avez trouv√©s (par exemple, 'La bonne r√©ponse est en fait B, et non A, d'apr√®s la phrase X', 'L'option C est trop vague', 'La question n'est pas pertinente par rapport au th√®me principal').",
        "   - **Suggestions d'Am√©lioration (Si N√©cessaire) :**",
        "     *   Si la question pr√©sente des d√©fauts, sugg√©rez une version r√©vis√©e de la question, des options ou de la bonne r√©ponse.",
        "     *   Si vous sugg√©rez de nouvelles options, assurez-vous qu'elles conservent le format QCM/FITB.",
        "     *   Si la question originale est bonne, indiquez qu'aucune am√©lioration significative n'est n√©cessaire.",
        "\nCommencez votre r√©ponse par votre avis g√©n√©ral. **R√©pondez int√©gralement en fran√ßais.**"
    ]
    full_prompt = "\n".join(prompt_parts)

    try:
        chat_completion = groq_client.chat.completions.create(
            messages=[
                {
                    "role": "system",
                    "content": "Vous √™tes un assistant IA qui √©value des questions p√©dagogiques. Fournissez des commentaires d√©taill√©s et des suggestions exclusivement en fran√ßais."
                },
                {
                    "role": "user",
                    "content": full_prompt,
                }
            ],
            model="llama3-70b-8192",
            temperature=0.2,
            max_tokens=2000,
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        return f"Erreur lors de l'appel √† l'API Groq : {str(e)}"

# --- Streamlit App Layout (Actual page content starts here) ---
st.title("üìù G√©n√©rateur de Questions avec V√©rification IA")
st.markdown("G√©n√©rez des QCM ou des Textes √† Trous, puis demandez √† une IA (Groq) de les analyser.")

# --- Session State ---
if 'text_input' not in st.session_state:
    st.session_state.text_input = ""
if 'question_type' not in st.session_state:
    st.session_state.question_type = "QCM"
if 'generated_data' not in st.session_state:
    st.session_state.generated_data = None
if 'raw_model_output' not in st.session_state:
    st.session_state.raw_model_output = ""
if 'verification_response' not in st.session_state:
    st.session_state.verification_response = None
if 'last_text_for_generation' not in st.session_state:
    st.session_state.last_text_for_generation = ""


# --- Input Area ---
st.subheader("1. Fournissez votre texte :")
text_area_input = st.text_area("Collez ou √©crivez votre texte ici :",
                               value=st.session_state.text_input,
                               height=250,
                               key="text_input_area")

if text_area_input != st.session_state.text_input:
    st.session_state.text_input = text_area_input
    st.session_state.generated_data = None
    st.session_state.raw_model_output = ""
    st.session_state.verification_response = None
    st.session_state.last_text_for_generation = ""

st.subheader("2. Choisissez le type de question :")
question_type_options = ('QCM (Question √† Choix Multiples)', 'FITB (Texte √† Trous / Fill-in-the-Blank)')
current_qt_index = 0 if st.session_state.question_type == "QCM" else 1
question_type_selection = st.radio(
    "Quel type de question souhaitez-vous g√©n√©rer ?",
    question_type_options,
    index=current_qt_index,
    key="question_type_radio"
)

new_question_type = "QCM" if question_type_selection == question_type_options[0] else "FITB"
if new_question_type != st.session_state.question_type:
    st.session_state.question_type = new_question_type
    st.session_state.generated_data = None
    st.session_state.raw_model_output = ""
    st.session_state.verification_response = None

# --- Generate Button ---
if st.button("üöÄ G√©n√©rer la question", type="primary", use_container_width=True):
    if not st.session_state.text_input.strip():
        st.warning("Veuillez entrer un texte avant de g√©n√©rer une question.")
    else:
        st.session_state.verification_response = None
        st.session_state.last_text_for_generation = st.session_state.text_input

        endpoint_to_call = QCM_ENDPOINT if st.session_state.question_type == "QCM" else FITB_ENDPOINT
        with st.spinner(f"G√©n√©ration de la question {st.session_state.question_type} en cours..."):
            api_response = call_flask_api(endpoint_to_call, st.session_state.text_input)
            st.session_state.generated_data = api_response
            st.session_state.raw_model_output = api_response.get("raw_output", "Aucune sortie brute disponible.")
            if "error" in api_response:
                 st.session_state.last_text_for_generation = "" # Don't allow verification if generation failed
            st.rerun()

# --- Display Area for Generated Question ---
if st.session_state.generated_data:
    st.divider()
    st.subheader(f"R√©sultat de la G√©n√©ration ({st.session_state.question_type})")

    data = st.session_state.generated_data

    if "error" in data and data["error"] != "Erreur de connexion API":
        error_message = data.get('details', {}).get('error', data.get('error', 'Erreur inconnue'))
        st.error(f"Erreur de l'API de g√©n√©ration: {error_message}")
        raw_output_key = "raw_output_on_error" if "raw_output_on_error" in data.get("details", {}) else "raw_output"
        raw_output_val = None
        if isinstance(data.get("details"), dict) and raw_output_key in data["details"]:
            raw_output_val = data["details"].get(raw_output_key)
        elif raw_output_key in data:
             raw_output_val = data.get(raw_output_key)
        
        if raw_output_val and raw_output_val != "Erreur API": # Avoid showing "Erreur API" as raw output if that's the content
            st.text_area("Sortie brute de l'API (sur erreur):", value=str(raw_output_val), height=150, disabled=True)

    elif data.get("question") and not data["question"].startswith("Could not parse"): # "Could not parse" is from your Flask app
        st.markdown(f"**Question :** {data.get('question', 'N/A')}")
        cols = st.columns(2)
        cols[0].markdown(f"**A)** {data.get('A', 'N/A')}")
        cols[0].markdown(f"**B)** {data.get('B', 'N/A')}")
        cols[1].markdown(f"**C)** {data.get('C', 'N/A')}")
        cols[1].markdown(f"**D)** {data.get('D', 'N/A')}")
        st.markdown(f"**R√©ponse correcte (par le mod√®le g√©n√©rateur) :** <span style='color:green; font-weight:bold;'>{data.get('reponse', 'N/A')}</span>", unsafe_allow_html=True)

        if groq_client and st.session_state.last_text_for_generation:
            if st.button("üîç V√©rifier avec l'IA (Groq)", key="verify_button", use_container_width=True):
                with st.spinner("L'IA de v√©rification analyse la question... (cela peut prendre un moment)"):
                    verification_result = call_groq_for_verification(
                        st.session_state.last_text_for_generation,
                        st.session_state.generated_data,
                        st.session_state.question_type
                    )
                    # Check if Groq call itself returned an error message
                    if verification_result.startswith("Erreur lors de l'appel √† l'API Groq") or \
                       verification_result.startswith("Client Groq non initialis√©"):
                        st.session_state.verification_response = None 
                        st.error(verification_result) 
                    else:
                        st.session_state.verification_response = verification_result
                    st.rerun()
        elif not groq_client:
            st.caption("Service de v√©rification IA (Groq) non disponible (v√©rifiez la cl√© API et le d√©marrage du client).")
        elif not st.session_state.last_text_for_generation:
             st.caption("G√©n√©rez d'abord une question avec succ√®s pour activer la v√©rification.")

    elif "raw_output" in data and data["raw_output"] and \
         data["raw_output"] not in ["Erreur de connexion API", "Erreur API", "Aucune sortie brute disponible.", "JSON invalide de l'API"]:
        st.warning("La g√©n√©ration a produit une sortie, mais elle n'a pas pu √™tre structur√©e correctement. V√©rifiez la sortie brute.")
    # Avoid showing generic error if a specific API error was already shown
    elif not ("error" in data and data["error"] != "Erreur de connexion API"): 
        if not (data.get("question") and not data["question"].startswith("Could not parse")): # If not already handled by successful display
            st.error("Aucune question n'a pu √™tre g√©n√©r√©e ou pars√©e. V√©rifiez la sortie brute si disponible.")


    if st.session_state.raw_model_output and \
       st.session_state.raw_model_output not in ["Erreur de connexion API", "Erreur API", "Aucune sortie brute disponible.", "JSON invalide de l'API"]:
        with st.expander("Afficher la sortie brute du mod√®le g√©n√©rateur", expanded=False):
            st.text_area("Sortie brute du g√©n√©rateur:", value=st.session_state.raw_model_output, height=200, disabled=True, key="raw_output_display")

# --- Display Area for Verification Response ---
if st.session_state.verification_response:
    st.divider()
    st.subheader("üïµÔ∏è‚Äç‚ôÇÔ∏è Analyse de l'IA de V√©rification (Groq)")
    st.markdown(st.session_state.verification_response)


if not st.session_state.text_input and not st.session_state.generated_data:
    st.info("Entrez un texte et cliquez sur 'G√©n√©rer la question' pour commencer.")

st.divider()
st.markdown("---")
st.markdown("<p style='text-align: center;'>D√©velopp√© avec Streamlit, llama.cpp & Groq</p>", unsafe_allow_html=True)

if st.button("üßπ Effacer et recommencer", use_container_width=True, key="clear_all"):
    st.session_state.text_input = ""
    st.session_state.question_type = "QCM"
    st.session_state.generated_data = None
    st.session_state.raw_model_output = ""
    st.session_state.verification_response = None
    st.session_state.last_text_for_generation = ""
    st.rerun()